{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb32bd59",
   "metadata": {},
   "source": [
    "# Pre Requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514959b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilize some helper functions saved in a separate file\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab8c74",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032f093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060d166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "test_df = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3f94ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943b529c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility frac =1 means the whole dataset is shuffled\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c9c1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no target column in test data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e17a4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts() #Fairly Balanced dataset and it's a Binary Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed1a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples:     3263\n",
      "Total samples:          10876\n"
     ]
    }
   ],
   "source": [
    "# Total number of samples\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples:     {len(test_df)}\")\n",
    "print(f\"Total samples:          {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81ca7d",
   "metadata": {},
   "source": [
    "# View 5 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "863dbcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "The Latest: More homes razed by Northern California wildfire: The latest on wildfires burning in California andÛ_ http://t.co/0Keh2TReNy\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I'm a tornado looking for a soul to take\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Coming later this year~ 'THE MAN THAT TATTOOED WOMEN.' A novel based on a real serial killer from #Arkansas &amp; a natural disaster. #NOLA\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "#FunnyNews #Business Watch the moment a cliff collapses as huge chunks of rock fall onto a road in China  http://t.co/LCi3pljX25\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Fascinating pics from inside North Korea. Not propaganda not devastation - just people living life. http://t.co/E2Dbcpwd9u\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random training examples\n",
    "\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():# '5' coz we're picking 5 samples and we don't want the index to go out of bounds\n",
    "  _, text, target = row #ignore the first column\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5dcf4",
   "metadata": {},
   "source": [
    "# Split into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda3ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c7cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953308b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10], train_labels[:10]   #sentences in text form and labels in numerical form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42d78a",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf6f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51c5215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2bc7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                     #   standardize=\"lower_and_strip_punctuation\",\n",
    "                                    #  split=\"whitespace\", # how to split tokens\n",
    "                                    # ngrams=None, # create groups of n-words\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f9214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd438c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 264,    3, 6980, 2472,    4,    2,  408,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a volcanic eruption in the area!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e85e68",
   "metadata": {},
   "source": [
    "The above text has been vectorized to 15 units and 7 words, rest are padded with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "129ff3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "'The man who can drive himself further once the effort gets painful is the man who will win.' \n",
      "Roger Bannister      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[   2,   89,   65,   71,  955, 1661, 2983,  838,    2, 2479,  742,\n",
       "        9991,    9,    2,   89]], dtype=int64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b641142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() #already assigned as max_tokens=max_vocab_length\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4584031b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'a',\n",
       " 'in',\n",
       " 'to',\n",
       " 'of',\n",
       " 'and',\n",
       " 'i',\n",
       " 'is',\n",
       " 'for',\n",
       " 'on',\n",
       " 'you',\n",
       " 'my',\n",
       " 'with',\n",
       " 'it',\n",
       " 'that',\n",
       " 'at',\n",
       " 'by',\n",
       " 'this',\n",
       " 'from',\n",
       " 'be',\n",
       " 'are',\n",
       " 'was',\n",
       " 'have',\n",
       " 'like',\n",
       " 'as',\n",
       " 'up',\n",
       " 'so',\n",
       " 'just',\n",
       " 'but',\n",
       " 'me',\n",
       " 'im',\n",
       " 'your',\n",
       " 'not',\n",
       " 'amp',\n",
       " 'out',\n",
       " 'its',\n",
       " 'will',\n",
       " 'an',\n",
       " 'no',\n",
       " 'has',\n",
       " 'fire',\n",
       " 'after',\n",
       " 'all',\n",
       " 'when',\n",
       " 'we',\n",
       " 'if',\n",
       " 'now',\n",
       " 'via',\n",
       " 'new',\n",
       " 'more',\n",
       " 'get',\n",
       " 'or',\n",
       " 'about',\n",
       " 'what',\n",
       " 'he',\n",
       " 'people',\n",
       " 'news',\n",
       " 'been',\n",
       " 'over',\n",
       " 'one',\n",
       " 'how',\n",
       " 'dont',\n",
       " 'they',\n",
       " 'who',\n",
       " 'into',\n",
       " 'were',\n",
       " 'do',\n",
       " 'us',\n",
       " '2',\n",
       " 'can',\n",
       " 'video',\n",
       " 'emergency',\n",
       " 'there',\n",
       " 'disaster',\n",
       " 'than',\n",
       " 'police',\n",
       " 'would',\n",
       " 'his',\n",
       " 'still',\n",
       " 'her',\n",
       " 'some',\n",
       " 'body',\n",
       " 'storm',\n",
       " 'crash',\n",
       " 'burning',\n",
       " 'suicide',\n",
       " 'back',\n",
       " 'man',\n",
       " 'california',\n",
       " 'why',\n",
       " 'time',\n",
       " 'them',\n",
       " 'had',\n",
       " 'buildings',\n",
       " 'rt',\n",
       " 'first',\n",
       " 'cant',\n",
       " 'see',\n",
       " 'got',\n",
       " 'day',\n",
       " 'off',\n",
       " 'our',\n",
       " 'going',\n",
       " 'nuclear',\n",
       " 'know',\n",
       " 'world',\n",
       " 'bomb',\n",
       " 'fires',\n",
       " 'love',\n",
       " 'killed',\n",
       " 'go',\n",
       " 'attack',\n",
       " 'youtube',\n",
       " 'dead',\n",
       " 'two',\n",
       " 'families',\n",
       " '3',\n",
       " 'train',\n",
       " 'full',\n",
       " 'being',\n",
       " 'war',\n",
       " 'many',\n",
       " 'today',\n",
       " 'think',\n",
       " 'only',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'life',\n",
       " 'hiroshima',\n",
       " 'their',\n",
       " 'say',\n",
       " 'may',\n",
       " 'down',\n",
       " 'watch',\n",
       " 'good',\n",
       " 'could',\n",
       " 'want',\n",
       " 'last',\n",
       " 'here',\n",
       " 'years',\n",
       " 'u',\n",
       " 'then',\n",
       " 'make',\n",
       " 'did',\n",
       " 'wildfire',\n",
       " 'way',\n",
       " 'help',\n",
       " 'best',\n",
       " 'too',\n",
       " 'even',\n",
       " 'because',\n",
       " 'home',\n",
       " 'death',\n",
       " 'collapse',\n",
       " 'bombing',\n",
       " 'mass',\n",
       " 'him',\n",
       " 'black',\n",
       " 'am',\n",
       " 'those',\n",
       " 'need',\n",
       " 'fatal',\n",
       " 'army',\n",
       " 'another',\n",
       " 'work',\n",
       " 'take',\n",
       " 'should',\n",
       " 'really',\n",
       " 'please',\n",
       " 'mh370',\n",
       " 'youre',\n",
       " 'look',\n",
       " 'lol',\n",
       " 'hot',\n",
       " 'pm',\n",
       " 'legionnaires',\n",
       " '4',\n",
       " 'right',\n",
       " '5',\n",
       " 'let',\n",
       " 'city',\n",
       " 'year',\n",
       " 'wreck',\n",
       " 'school',\n",
       " 'northern',\n",
       " 'much',\n",
       " 'forest',\n",
       " 'bomber',\n",
       " 'water',\n",
       " 'she',\n",
       " 'never',\n",
       " 'read',\n",
       " 'latest',\n",
       " 'homes',\n",
       " 'great',\n",
       " 'every',\n",
       " '1',\n",
       " 'live',\n",
       " 'god',\n",
       " 'fear',\n",
       " 'any',\n",
       " '\\x89Û',\n",
       " 'under',\n",
       " 'said',\n",
       " 'old',\n",
       " 'floods',\n",
       " '2015',\n",
       " 'getting',\n",
       " 'atomic',\n",
       " 'while',\n",
       " 'top',\n",
       " 'obama',\n",
       " 'feel',\n",
       " 'thats',\n",
       " 'since',\n",
       " 'near',\n",
       " 'flames',\n",
       " 'ever',\n",
       " 'come',\n",
       " 'where',\n",
       " 'these',\n",
       " 'military',\n",
       " 'japan',\n",
       " 'found',\n",
       " 'content',\n",
       " 'ass',\n",
       " 'without',\n",
       " 'weather',\n",
       " 'most',\n",
       " 'flooding',\n",
       " 'flood',\n",
       " 'damage',\n",
       " 'which',\n",
       " 'shit',\n",
       " 's',\n",
       " 'hope',\n",
       " 'everyone',\n",
       " 'before',\n",
       " 'stop',\n",
       " 'plan',\n",
       " 'malaysia',\n",
       " 'injured',\n",
       " 'hit',\n",
       " 'evacuation',\n",
       " 'during',\n",
       " 'debris',\n",
       " 'cross',\n",
       " 'coming',\n",
       " 'wild',\n",
       " 'well',\n",
       " 'times',\n",
       " 'sinking',\n",
       " 'oil',\n",
       " 'fucking',\n",
       " 'check',\n",
       " 'cause',\n",
       " 'weapons',\n",
       " 'truck',\n",
       " 'food',\n",
       " 'bloody',\n",
       " 'always',\n",
       " 'weapon',\n",
       " 'theres',\n",
       " 'state',\n",
       " 'little',\n",
       " 'injuries',\n",
       " 'free',\n",
       " 'wounded',\n",
       " 'summer',\n",
       " 'smoke',\n",
       " 'severe',\n",
       " 'reddit',\n",
       " 'next',\n",
       " 'movie',\n",
       " 'ive',\n",
       " 'hes',\n",
       " 'fall',\n",
       " 'evacuate',\n",
       " 'confirmed',\n",
       " 'bad',\n",
       " 'again',\n",
       " 'thunderstorm',\n",
       " 'set',\n",
       " 'night',\n",
       " 'natural',\n",
       " 'looks',\n",
       " 'heat',\n",
       " 'face',\n",
       " 'earthquake',\n",
       " 'boy',\n",
       " 'whole',\n",
       " 'until',\n",
       " 'thunder',\n",
       " 'through',\n",
       " 'says',\n",
       " 'panic',\n",
       " 'outbreak',\n",
       " 'made',\n",
       " 'lightning',\n",
       " 'fatalities',\n",
       " 'family',\n",
       " 'explosion',\n",
       " 'end',\n",
       " 'destroy',\n",
       " 'derailment',\n",
       " 'air',\n",
       " 'w',\n",
       " 'terrorist',\n",
       " 'survive',\n",
       " 'screaming',\n",
       " 'saudi',\n",
       " 'refugees',\n",
       " 'rain',\n",
       " 'murder',\n",
       " 'loud',\n",
       " 'liked',\n",
       " 'house',\n",
       " 'gonna',\n",
       " 'failure',\n",
       " 'collided',\n",
       " 'bag',\n",
       " 'attacked',\n",
       " 'ambulance',\n",
       " '70',\n",
       " 'wind',\n",
       " 'services',\n",
       " 'save',\n",
       " 'report',\n",
       " 'migrants',\n",
       " 'head',\n",
       " 'explode',\n",
       " 'charged',\n",
       " 'change',\n",
       " 'big',\n",
       " 'also',\n",
       " 'wrecked',\n",
       " 'warning',\n",
       " 'update',\n",
       " 'run',\n",
       " 'rescuers',\n",
       " 'released',\n",
       " 'photo',\n",
       " 'massacre',\n",
       " 'injury',\n",
       " 'hurricane',\n",
       " 'high',\n",
       " 'hail',\n",
       " 'fuck',\n",
       " 'does',\n",
       " 'destroyed',\n",
       " 'bus',\n",
       " 'blood',\n",
       " '40',\n",
       " '\\x89ÛÒ',\n",
       " 'wreckage',\n",
       " 'violent',\n",
       " 'twister',\n",
       " 'trauma',\n",
       " 'tragedy',\n",
       " 'terrorism',\n",
       " 'survivors',\n",
       " 'survived',\n",
       " 'sinkhole',\n",
       " 'sandstorm',\n",
       " 'road',\n",
       " 'rioting',\n",
       " 'red',\n",
       " 'real',\n",
       " 'put',\n",
       " 'post',\n",
       " 'national',\n",
       " 'missing',\n",
       " 'landslide',\n",
       " 'keep',\n",
       " 'girl',\n",
       " 'drought',\n",
       " 'curfew',\n",
       " 'breaking',\n",
       " 'bags',\n",
       " 'white',\n",
       " 'twitter',\n",
       " 'tonight',\n",
       " 'structural',\n",
       " 'spill',\n",
       " 'service',\n",
       " 'screamed',\n",
       " 'rescued',\n",
       " 'rescue',\n",
       " 'phone',\n",
       " 'ok',\n",
       " 'oh',\n",
       " 'mosque',\n",
       " 'lives',\n",
       " 'horrible',\n",
       " 'harm',\n",
       " 'game',\n",
       " 'dust',\n",
       " 'destruction',\n",
       " 'deluge',\n",
       " 'deaths',\n",
       " 'crashed',\n",
       " 'cliff',\n",
       " 'catastrophe',\n",
       " 'boat',\n",
       " 'away',\n",
       " 'august',\n",
       " 'area',\n",
       " 'apocalypse',\n",
       " 'woman',\n",
       " 'whirlwind',\n",
       " 'traumatised',\n",
       " 'stock',\n",
       " 'saw',\n",
       " 'ruin',\n",
       " 'riot',\n",
       " 'quarantine',\n",
       " 'kills',\n",
       " 'island',\n",
       " 'investigators',\n",
       " 'ill',\n",
       " 'hostages',\n",
       " 'hazard',\n",
       " 'danger',\n",
       " 'call',\n",
       " '15',\n",
       " 'women',\n",
       " 'windstorm',\n",
       " 'things',\n",
       " 'suspect',\n",
       " 'show',\n",
       " 'reunion',\n",
       " 'quarantined',\n",
       " 'lava',\n",
       " 'heart',\n",
       " 'engulfed',\n",
       " 'detonate',\n",
       " 'crush',\n",
       " 'collapsed',\n",
       " 'came',\n",
       " 'better',\n",
       " 'battle',\n",
       " 'armageddon',\n",
       " 'airplane',\n",
       " 'against',\n",
       " 'affected',\n",
       " 'use',\n",
       " 'trapped',\n",
       " 'thank',\n",
       " 'sunk',\n",
       " 'story',\n",
       " 'send',\n",
       " 'part',\n",
       " 'other',\n",
       " 'must',\n",
       " 'mudslide',\n",
       " 'market',\n",
       " 'iran',\n",
       " 'famine',\n",
       " 'exploded',\n",
       " 'electrocuted',\n",
       " 'ebay',\n",
       " 'displaced',\n",
       " 'derailed',\n",
       " 'derail',\n",
       " 'burned',\n",
       " 'bombed',\n",
       " 'blown',\n",
       " 'baby',\n",
       " 'around',\n",
       " 'zone',\n",
       " 'wave',\n",
       " 'wanna',\n",
       " 'sure',\n",
       " 'someone',\n",
       " 'screams',\n",
       " 'razed',\n",
       " 'power',\n",
       " 'obliterated',\n",
       " 'long',\n",
       " 'land',\n",
       " 'hundreds',\n",
       " 'heard',\n",
       " 'group',\n",
       " 'flattened',\n",
       " 'drown',\n",
       " 'doing',\n",
       " 'care',\n",
       " 'bridge',\n",
       " 'bagging',\n",
       " '9',\n",
       " 'went',\n",
       " 'used',\n",
       " 'typhoon',\n",
       " 'trouble',\n",
       " 'tornado',\n",
       " 'thought',\n",
       " 'thing',\n",
       " 'river',\n",
       " 'responders',\n",
       " 'past',\n",
       " 'pandemonium',\n",
       " 'officials',\n",
       " 'meltdown',\n",
       " 'lot',\n",
       " 'least',\n",
       " 'inundated',\n",
       " 'id',\n",
       " 'hostage',\n",
       " 'hijacking',\n",
       " 'hazardous',\n",
       " 'goes',\n",
       " 'drowning',\n",
       " 'didnt',\n",
       " 'devastation',\n",
       " 'demolish',\n",
       " 'collide',\n",
       " 'casualties',\n",
       " 'calgary',\n",
       " 'bang',\n",
       " 'anniversary',\n",
       " 'yet',\n",
       " 'wounds',\n",
       " 'volcano',\n",
       " 'tsunami',\n",
       " 'sue',\n",
       " 'st',\n",
       " 'song',\n",
       " 'something',\n",
       " 'shoulder',\n",
       " 'security',\n",
       " 'prebreak',\n",
       " 'possible',\n",
       " 'pkk',\n",
       " 'panicking',\n",
       " 'obliteration',\n",
       " 'obliterate',\n",
       " 'murderer',\n",
       " 'minute',\n",
       " 'light',\n",
       " 'lets',\n",
       " 'kill',\n",
       " 'isis',\n",
       " 'india',\n",
       " 'hijacker',\n",
       " 'hellfire',\n",
       " 'government',\n",
       " 'few',\n",
       " 'evacuated',\n",
       " 'due',\n",
       " 'detonated',\n",
       " 'desolation',\n",
       " 'crushed',\n",
       " 'chemical',\n",
       " 'blew',\n",
       " 'blazing',\n",
       " 'blast',\n",
       " 'annihilated',\n",
       " 'airport',\n",
       " '6',\n",
       " 'week',\n",
       " 'upheaval',\n",
       " 'trying',\n",
       " 'three',\n",
       " 'thanks',\n",
       " 'sound',\n",
       " 'soon',\n",
       " 'sirens',\n",
       " 'rainstorm',\n",
       " 'plane',\n",
       " 'music',\n",
       " 'making',\n",
       " 'kids',\n",
       " 'issues',\n",
       " 'half',\n",
       " 'guys',\n",
       " 'fedex',\n",
       " 'done',\n",
       " 'died',\n",
       " 'detonation',\n",
       " 'days',\n",
       " 'cyclone',\n",
       " 'county',\n",
       " 'collision',\n",
       " 'caused',\n",
       " 'catastrophic',\n",
       " 'bleeding',\n",
       " 'beautiful',\n",
       " '8',\n",
       " 'words',\n",
       " 'very',\n",
       " 'traffic',\n",
       " 'south',\n",
       " 'remember',\n",
       " 'policy',\n",
       " 'place',\n",
       " 'nothing',\n",
       " 'north',\n",
       " 'mp',\n",
       " 'longer',\n",
       " 'left',\n",
       " 'israeli',\n",
       " 'hell',\n",
       " 'fun',\n",
       " 'drowned',\n",
       " 'demolished',\n",
       " 'cool',\n",
       " 'both',\n",
       " 'bioterror',\n",
       " 'believe',\n",
       " 'avalanche',\n",
       " 'arson',\n",
       " 'turkey',\n",
       " 'snowstorm',\n",
       " 'site',\n",
       " 'shot',\n",
       " 'shooting',\n",
       " 'pic',\n",
       " 'nowplaying',\n",
       " 'media',\n",
       " 'islam',\n",
       " 'inside',\n",
       " 'hijack',\n",
       " 'helicopter',\n",
       " 'fight',\n",
       " 'fatality',\n",
       " 'fan',\n",
       " 'electrocute',\n",
       " 'doesnt',\n",
       " 'building',\n",
       " 'brown',\n",
       " 'bc',\n",
       " 'actually',\n",
       " '16yr',\n",
       " 'yes',\n",
       " 'watching',\n",
       " 'wait',\n",
       " 'ur',\n",
       " 'tell',\n",
       " 'swallowed',\n",
       " 'seismic',\n",
       " 'second',\n",
       " 'rubble',\n",
       " 're\\x89Û',\n",
       " 'plans',\n",
       " 'men',\n",
       " 'memories',\n",
       " 'line',\n",
       " 'la',\n",
       " 'horror',\n",
       " 'health',\n",
       " 'having',\n",
       " 'find',\n",
       " 'eyewitness',\n",
       " 'deluged',\n",
       " 'children',\n",
       " 'bush',\n",
       " 'anything',\n",
       " 'already',\n",
       " 'almost',\n",
       " 'aircraft',\n",
       " 'yourself',\n",
       " 'yeah',\n",
       " 'whats',\n",
       " 'tomorrow',\n",
       " 'such',\n",
       " 'start',\n",
       " 'side',\n",
       " 'searching',\n",
       " 'saved',\n",
       " 'reactor',\n",
       " 'probably',\n",
       " 'play',\n",
       " 'person',\n",
       " 'peace',\n",
       " 'outside',\n",
       " 'officer',\n",
       " 'nearby',\n",
       " 'n',\n",
       " 'maybe',\n",
       " 'lost',\n",
       " 'literally',\n",
       " 'hours',\n",
       " 'hear',\n",
       " 'far',\n",
       " 'die',\n",
       " 'demolition',\n",
       " 'data',\n",
       " 'crews',\n",
       " 'conclusively',\n",
       " 'business',\n",
       " 'american',\n",
       " '20',\n",
       " '\\x89ÛÓ',\n",
       " 'west',\n",
       " 'waves',\n",
       " 'team',\n",
       " 'street',\n",
       " 'stay',\n",
       " 'soudelor',\n",
       " 'reuters',\n",
       " 'manslaughter',\n",
       " 'leather',\n",
       " 'job',\n",
       " 'history',\n",
       " 'hey',\n",
       " 'feeling',\n",
       " 'eyes',\n",
       " 'everything',\n",
       " 'declares',\n",
       " 'deal',\n",
       " 'casualty',\n",
       " 'bodies',\n",
       " 'amid',\n",
       " 'ablaze',\n",
       " '7',\n",
       " '50',\n",
       " '30',\n",
       " '12',\n",
       " 'youth',\n",
       " 'wont',\n",
       " 'wake',\n",
       " 'theyre',\n",
       " 'support',\n",
       " 'stretcher',\n",
       " 'same',\n",
       " 'rise',\n",
       " 'picking',\n",
       " 'photos',\n",
       " 'own',\n",
       " 'others',\n",
       " 'order',\n",
       " 'omg',\n",
       " 'okay',\n",
       " 'name',\n",
       " 'myself',\n",
       " 'money',\n",
       " 'makes',\n",
       " 'leave',\n",
       " 'lab',\n",
       " 'gt',\n",
       " 'gets',\n",
       " 'flag',\n",
       " 'desolate',\n",
       " 'crisis',\n",
       " 'center',\n",
       " 'book',\n",
       " 'blight',\n",
       " 'blaze',\n",
       " 'ago',\n",
       " 'abc',\n",
       " '11yearold',\n",
       " 'womens',\n",
       " 'typhoondevastated',\n",
       " 'tv',\n",
       " 'trench',\n",
       " 'trains',\n",
       " 'texas',\n",
       " 'space',\n",
       " 'siren',\n",
       " 'shes',\n",
       " 'self',\n",
       " 'saipan',\n",
       " 'reason',\n",
       " 'rd',\n",
       " 'pretty',\n",
       " 'pick',\n",
       " 'offensive',\n",
       " 'move',\n",
       " 'meek',\n",
       " 'major',\n",
       " 'm',\n",
       " 'low',\n",
       " 'lord',\n",
       " 'huge',\n",
       " 'hat',\n",
       " 'flash',\n",
       " 'feared',\n",
       " 'fast',\n",
       " 'effect',\n",
       " 'course',\n",
       " 'country',\n",
       " 'control',\n",
       " 'class',\n",
       " 'child',\n",
       " 'chance',\n",
       " 'caught',\n",
       " 'called',\n",
       " 'bioterrorism',\n",
       " 'bestnaijamade',\n",
       " 'become',\n",
       " 'bar',\n",
       " 'banned',\n",
       " 'ball',\n",
       " 'aug',\n",
       " 'annihilation',\n",
       " 'wrong',\n",
       " 'win',\n",
       " 'usa',\n",
       " 'united',\n",
       " 'town',\n",
       " 'totally',\n",
       " 'toddler',\n",
       " 'though',\n",
       " 'temple',\n",
       " 'taken',\n",
       " 'stand',\n",
       " 'spot',\n",
       " 'signs',\n",
       " 'ship',\n",
       " 'pakistan',\n",
       " 'online',\n",
       " 'level',\n",
       " 'ladies',\n",
       " 'jobs',\n",
       " 'isnt',\n",
       " 'happy',\n",
       " 'hailstorm',\n",
       " 'friends',\n",
       " 'disea',\n",
       " 'damn',\n",
       " 'couple',\n",
       " 'case',\n",
       " 'blue',\n",
       " 'bigger',\n",
       " 'america',\n",
       " 'across',\n",
       " '10',\n",
       " 'yours',\n",
       " 'village',\n",
       " 'try',\n",
       " 'transport',\n",
       " 'talk',\n",
       " 'seen',\n",
       " 'russian',\n",
       " 'radio',\n",
       " 'projected',\n",
       " 'once',\n",
       " 'official',\n",
       " 'needs',\n",
       " 'nearly',\n",
       " 'mount',\n",
       " 'might',\n",
       " 'mayhem',\n",
       " 'instead',\n",
       " 'hollywood',\n",
       " 'haha',\n",
       " 'guy',\n",
       " 'gun',\n",
       " 'green',\n",
       " 'front',\n",
       " 'finally',\n",
       " 'favorite',\n",
       " 'experts',\n",
       " 'entire',\n",
       " 'east',\n",
       " 'daily',\n",
       " 'crazy',\n",
       " 'computers',\n",
       " 'coaches',\n",
       " 'christian',\n",
       " 'china',\n",
       " 'blizzard',\n",
       " 'anyone',\n",
       " 'aint',\n",
       " 'action',\n",
       " '25',\n",
       " 'virgin',\n",
       " 'vehicle',\n",
       " 'truth',\n",
       " 'trust',\n",
       " 'takes',\n",
       " 't',\n",
       " 'star',\n",
       " 'sorry',\n",
       " 'running',\n",
       " 'refugio',\n",
       " 'reddits',\n",
       " 'poor',\n",
       " 'pain',\n",
       " 'mom',\n",
       " 'miners',\n",
       " 'marks',\n",
       " 'looking',\n",
       " 'knock',\n",
       " 'issued',\n",
       " 'insurance',\n",
       " 'ignition',\n",
       " 'houses',\n",
       " 'heavy',\n",
       " 'hate',\n",
       " 'hard',\n",
       " 'happened',\n",
       " 'global',\n",
       " 'giant',\n",
       " 'gbbo',\n",
       " 'flight',\n",
       " 'eye',\n",
       " 'emmerdale',\n",
       " 'driver',\n",
       " 'devastated',\n",
       " 'd',\n",
       " 'costlier',\n",
       " 'cnn',\n",
       " 'cars',\n",
       " 'camp',\n",
       " 'beach',\n",
       " 'arsonist',\n",
       " 'angry',\n",
       " 'alone',\n",
       " 'added',\n",
       " '05',\n",
       " 'york',\n",
       " 'wonder',\n",
       " 'uk',\n",
       " 'turn',\n",
       " 'taking',\n",
       " 'subreddits',\n",
       " 'sounds',\n",
       " 'scared',\n",
       " 'russia',\n",
       " 'rly',\n",
       " 'reports',\n",
       " 'ready',\n",
       " 'quiz',\n",
       " 'public',\n",
       " 'property',\n",
       " 'pradesh',\n",
       " 'ppl',\n",
       " 'playing',\n",
       " 'pay',\n",
       " 'parole',\n",
       " 'pamela',\n",
       " 'pakistani',\n",
       " 'outrage',\n",
       " 'niggas',\n",
       " 'nagasaki',\n",
       " 'myanmar',\n",
       " 'muslims',\n",
       " 'mop',\n",
       " 'madhya',\n",
       " 'mad',\n",
       " 'lmao',\n",
       " 'learn',\n",
       " 'large',\n",
       " 'govt',\n",
       " 'give',\n",
       " 'gems',\n",
       " 'gave',\n",
       " 'funtenna',\n",
       " 'fukushima',\n",
       " 'former',\n",
       " 'film',\n",
       " 'earth',\n",
       " 'drive',\n",
       " 'downtown',\n",
       " 'dog',\n",
       " 'comes',\n",
       " 'closed',\n",
       " 'cake',\n",
       " 'british',\n",
       " 'bring',\n",
       " 'bbc',\n",
       " 'b',\n",
       " 'appears',\n",
       " 'aftershock',\n",
       " '13',\n",
       " '11',\n",
       " 'young',\n",
       " 'wow',\n",
       " 'worst',\n",
       " 'waving',\n",
       " 'washington',\n",
       " 'wanted',\n",
       " 'vs',\n",
       " 'view',\n",
       " 'upon',\n",
       " 'tweet',\n",
       " 'tree',\n",
       " 'tote',\n",
       " 'thousands',\n",
       " 'thinking',\n",
       " 'theater',\n",
       " 'soul',\n",
       " 'sky',\n",
       " 'sign',\n",
       " 'shows',\n",
       " 'shift',\n",
       " 'seeing',\n",
       " 'sea',\n",
       " 'scene',\n",
       " 'safety',\n",
       " 'rules',\n",
       " 'rock',\n",
       " 'reported',\n",
       " 'r',\n",
       " 'pray',\n",
       " 'playlist',\n",
       " 'patience',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vocab #goes from most commonly used to rarely used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a75409",
   "metadata": {},
   "source": [
    "## Now to Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc06b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x28888968fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fc6083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "@fewmoretweets all lives matter. Just not a fan of burning down buildings and stealing from your neighbors to 'protest'      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "          0.03332629,  0.02803668],\n",
       "        [-0.04755558,  0.01773831, -0.03848469, ..., -0.03399577,\n",
       "         -0.04253842, -0.04712509],\n",
       "        [ 0.03603521, -0.01872348,  0.00094754, ...,  0.03704604,\n",
       "         -0.02932191,  0.01167182],\n",
       "        ...,\n",
       "        [ 0.02248487, -0.02848336,  0.04786098, ...,  0.03069806,\n",
       "         -0.04317403, -0.04145076],\n",
       "        [ 0.01736889,  0.02054228,  0.03813318, ...,  0.00564801,\n",
       "         -0.00274082, -0.04247797],\n",
       "        [-0.03769413, -0.00289064, -0.03677417, ..., -0.04211248,\n",
       "         -0.03247404,  0.04107854]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80681593",
   "metadata": {},
   "source": [
    "The above Embedding version is a learned representation of numbers that get initialized randomly but learn as they pass through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed571fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 0.03977952, -0.03782602, -0.03646283, -0.02449075, -0.00015752,\n",
       "        0.02220254,  0.00162981,  0.00603487,  0.0085157 , -0.02620113,\n",
       "        0.04101599,  0.03715892,  0.02397566,  0.00281113, -0.02704906,\n",
       "       -0.04870148,  0.01457943,  0.0059551 , -0.02334484,  0.03581132,\n",
       "        0.04377897,  0.04186075,  0.03245703, -0.045092  ,  0.04260418,\n",
       "        0.03398135, -0.01812425, -0.03539513,  0.02954218,  0.02556742,\n",
       "       -0.03345481,  0.04272738, -0.00798845, -0.0406163 , -0.00644834,\n",
       "        0.00232404,  0.01703629,  0.03645121, -0.02622857,  0.03498118,\n",
       "       -0.03059715,  0.02576998, -0.04221511,  0.02654583, -0.02192564,\n",
       "       -0.0346157 ,  0.00075326,  0.01427345,  0.01027539, -0.04311384,\n",
       "       -0.03973336, -0.00966626,  0.01032177, -0.04011822, -0.018892  ,\n",
       "       -0.01233201,  0.02721632, -0.01232889, -0.02504088, -0.04715574,\n",
       "        0.00558523, -0.00801403,  0.03058865, -0.01923352, -0.04175536,\n",
       "       -0.03654208, -0.04277095, -0.0033918 , -0.04226271,  0.0240727 ,\n",
       "        0.01274442, -0.00268712,  0.03158386,  0.04823284,  0.02940297,\n",
       "        0.00636031,  0.01719667,  0.03907609, -0.0249153 , -0.00834242,\n",
       "        0.03881217, -0.04461795,  0.03740455, -0.02412283, -0.01538421,\n",
       "        0.03984089, -0.04073881,  0.0317078 , -0.04241145, -0.03435747,\n",
       "        0.03021734,  0.0443267 ,  0.00424304, -0.01204874, -0.00213076,\n",
       "       -0.02668054,  0.0461436 , -0.04644201,  0.02519932, -0.04503984,\n",
       "       -0.03163396, -0.02846084,  0.01276297,  0.02938429,  0.03437588,\n",
       "        0.00973482, -0.01860742,  0.03510927, -0.04996962,  0.01983938,\n",
       "        0.00642185,  0.00372197,  0.01576127,  0.01591486, -0.04195998,\n",
       "        0.02777341,  0.00619875, -0.02269079, -0.00224097,  0.0289592 ,\n",
       "        0.04377018, -0.03377642,  0.00907839, -0.01134553, -0.02910458,\n",
       "        0.00236253,  0.03332629,  0.02803668], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304b9a4",
   "metadata": {},
   "source": [
    "# Creating a baseline model using traditional ML (Naive Bayes) model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "526d33ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c0f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99807736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "670abaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a813de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e880f",
   "metadata": {},
   "source": [
    "# Creating a Simple Dense Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd617791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cc03f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # sigmoid squashes any input value to a range between 0 and 1\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a6117b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\", #used in binary problems when the output is 0 or 1\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27507504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28088e",
   "metadata": {},
   "source": [
    "The 1280129 parameters are coz of 128 dim embeddings into 10,000 max tokens/vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "710f9d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20250307-034121\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 14ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
    "                                                                     experiment_name=\"simple_dense_model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "826f3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47668465971946716, 0.787401556968689]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7845bbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
       " array([[ 0.00073164,  0.01504797, -0.03425452, ..., -0.04403543,\n",
       "         -0.01042278,  0.01876435],\n",
       "        [ 0.04135864, -0.03945082, -0.03811941, ...,  0.00464735,\n",
       "          0.03163553,  0.02928305],\n",
       "        [ 0.00684032,  0.05363133, -0.00241555, ..., -0.07082175,\n",
       "         -0.04750698,  0.01448254],\n",
       "        ...,\n",
       "        [-0.03301444, -0.0052493 , -0.04209725, ...,  0.02028764,\n",
       "          0.00308807,  0.02215792],\n",
       "        [ 0.00692342,  0.05942352, -0.01975194, ..., -0.06199061,\n",
       "         -0.01018394,  0.0351042 ],\n",
       "        [-0.0372346 ,  0.06267188, -0.07451148, ..., -0.02367217,\n",
       "         -0.08643331,  0.01742156]], dtype=float32)>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4845afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape)   # for 10k max vocab and 128 dim vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "492202a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.404882  ],\n",
       "       [0.7443312 ],\n",
       "       [0.997895  ],\n",
       "       [0.10889997],\n",
       "       [0.1114353 ],\n",
       "       [0.9355609 ],\n",
       "       [0.9134594 ],\n",
       "       [0.99253446],\n",
       "       [0.9715681 ],\n",
       "       [0.2657034 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44fd75fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7398d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7914920592553047,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.7846966492209201}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa7b99a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is our simple Dense model better than our baseline Naive bayes model?\n",
    "# checking the values of accuracy, precision, recall and f1 score\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adeb32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04b131cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56b698c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00073164  0.01504797 -0.03425452 ... -0.04403543 -0.01042278\n",
      "   0.01876435]\n",
      " [ 0.04135864 -0.03945082 -0.03811941 ...  0.00464735  0.03163553\n",
      "   0.02928305]\n",
      " [ 0.00684032  0.05363133 -0.00241555 ... -0.07082175 -0.04750698\n",
      "   0.01448254]\n",
      " ...\n",
      " [-0.03301444 -0.0052493  -0.04209725 ...  0.02028764  0.00308807\n",
      "   0.02215792]\n",
      " [ 0.00692342  0.05942352 -0.01975194 ... -0.06199061 -0.01018394\n",
      "   0.0351042 ]\n",
      " [-0.0372346   0.06267188 -0.07451148 ... -0.02367217 -0.08643331\n",
      "   0.01742156]]\n",
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer \n",
    "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights) #updated weights as the model learns\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ffa4508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abd6ba",
   "metadata": {},
   "source": [
    "# Creating Model 2 with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2f9f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_2\")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\\ relu makes -ve into 0, if +ve remains unchanged\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a17fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f7bb7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20250307-034137\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 25ms/step - loss: 0.5105 - accuracy: 0.7475 - val_loss: 0.4579 - val_accuracy: 0.7808\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.3205 - accuracy: 0.8701 - val_loss: 0.4992 - val_accuracy: 0.7769\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.2233 - accuracy: 0.9145 - val_loss: 0.5533 - val_accuracy: 0.7559\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1621 - accuracy: 0.9432 - val_loss: 0.6374 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1118 - accuracy: 0.9585 - val_loss: 0.8779 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "320edc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 64)            49408     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,366,657\n",
      "Trainable params: 1,366,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bda0134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[1.7079480e-02],\n",
       "        [6.6736013e-01],\n",
       "        [9.9978411e-01],\n",
       "        [3.3760622e-02],\n",
       "        [8.3615648e-04],\n",
       "        [9.9988747e-01],\n",
       "        [8.7640941e-01],\n",
       "        [9.9992561e-01],\n",
       "        [9.9987233e-01],\n",
       "        [1.9446409e-01]], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2f9f3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "932709a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.37795275590551,\n",
       " 'precision': 0.766310461192351,\n",
       " 'recall': 0.7637795275590551,\n",
       " 'f1': 0.7610762606610089}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fab402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.38, Difference: -2.89\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
     ]
    }
   ],
   "source": [
    "# Compare model 2 to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d223f8",
   "metadata": {},
   "source": [
    "# Creating Model 3 using GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb95743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_3\")\n",
    "\n",
    "# Build an RNN using the GRU cell\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "x = layers.GRU(64, return_sequences=True)(x) # stacking recurrent cells requires return_sequences=True\n",
    "x = layers.GRU(64)(x) \n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fc9a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ca48cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 15, 64)            37248     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,346,433\n",
      "Trainable params: 1,346,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the GRU model\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5b2f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/GRU/20250307-034204\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 22ms/step - loss: 0.5240 - accuracy: 0.7348 - val_loss: 0.4501 - val_accuracy: 0.7887\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.3249 - accuracy: 0.8662 - val_loss: 0.4909 - val_accuracy: 0.7822\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.2244 - accuracy: 0.9155 - val_loss: 0.5359 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1628 - accuracy: 0.9432 - val_loss: 0.6398 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1215 - accuracy: 0.9594 - val_loss: 0.6044 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84d1c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.30182013],\n",
       "        [0.79580885],\n",
       "        [0.99748313],\n",
       "        [0.17182574],\n",
       "        [0.0114118 ],\n",
       "        [0.99277   ],\n",
       "        [0.64600194],\n",
       "        [0.99678236],\n",
       "        [0.99766237],\n",
       "        [0.25952685]], dtype=float32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cc607fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ce9f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7701965974536404,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7694283709964855}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73b783c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84a7a8",
   "metadata": {},
   "source": [
    "# Model 4 using BiDirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "676736f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8bd8f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8205ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,761\n",
      "Trainable params: 1,477,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our bidirectional model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fc46777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20250307-034230\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 14s 29ms/step - loss: 0.5057 - accuracy: 0.7501 - val_loss: 0.4546 - val_accuracy: 0.7887\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.3115 - accuracy: 0.8768 - val_loss: 0.5145 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.2098 - accuracy: 0.9187 - val_loss: 0.5697 - val_accuracy: 0.7559\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.1417 - accuracy: 0.9512 - val_loss: 0.6899 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.7046 - val_accuracy: 0.7664\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7287bb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00695204],\n",
       "       [0.8773243 ],\n",
       "       [0.99736065],\n",
       "       [0.13291574],\n",
       "       [0.00910186],\n",
       "       [0.997924  ],\n",
       "       [0.82542646],\n",
       "       [0.9994547 ],\n",
       "       [0.9984187 ],\n",
       "       [0.1746117 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea6e6464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "695cb36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.64041994750657,\n",
       " 'precision': 0.771218657508237,\n",
       " 'recall': 0.7664041994750657,\n",
       " 'f1': 0.7627908927491446}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e77bf84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.76, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Check to see how the bidirectional model performs against the baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e45d6",
   "metadata": {},
   "source": [
    "# Model 5 using Cov1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "936ff132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_5\")\n",
    "\n",
    "# Create 1-dimensional convolutional layer to model sequences\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "132ee9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Conv1D model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b26a2ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20250307-034304\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 19ms/step - loss: 0.5559 - accuracy: 0.7116 - val_loss: 0.4681 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.3114 - accuracy: 0.8781 - val_loss: 0.5056 - val_accuracy: 0.7822\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.1641 - accuracy: 0.9447 - val_loss: 0.5470 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.1025 - accuracy: 0.9680 - val_loss: 0.6080 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.6318 - val_accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"Conv1D\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9529e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 15)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,302,689\n",
      "Trainable params: 1,302,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get a summary of our 1D convolution model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bcc05380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.25945702],\n",
       "       [0.7059047 ],\n",
       "       [0.999485  ],\n",
       "       [0.05618268],\n",
       "       [0.00756932],\n",
       "       [0.99552774],\n",
       "       [0.89148456],\n",
       "       [0.99517894],\n",
       "       [0.9983709 ],\n",
       "       [0.15831214]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52e30210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "169ca87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.34645669291339,\n",
       " 'precision': 0.7872123378365872,\n",
       " 'recall': 0.7834645669291339,\n",
       " 'f1': 0.7807800582578167}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_5 evaluation metrics \n",
    "model_5_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3b56d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.35, Difference: -0.92\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Compare model_5 results to baseline \n",
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf89839",
   "metadata": {},
   "source": [
    "# Model 6: TensorFlow Hub Pretrained Sentence Encoder¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af8cb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence encoder creating embedding for whole sentence instead of just word level like we did for previous models\n",
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7521878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01919626  0.03580806 -0.01051746  0.00803717  0.03318942 -0.01937674\n",
      "  0.05923755 -0.00114248  0.0269969   0.03682643  0.02981899  0.00664008\n",
      "  0.00420282  0.06707849  0.00270443 -0.05176902 -0.0445304  -0.02926458\n",
      " -0.01439998 -0.02365554 -0.04606229 -0.00337202  0.02348704  0.08446364\n",
      " -0.05276516 -0.0546678   0.03179989  0.01261172 -0.02797169 -0.00228025\n",
      " -0.06416498 -0.03120591 -0.04923686  0.03188515 -0.0081309   0.07574863\n",
      " -0.03623925  0.07664614  0.01958211  0.00083611 -0.05661529  0.02020875\n",
      "  0.00689054  0.05636149 -0.08412047  0.01122623  0.01917547 -0.03058512\n",
      "  0.05984719 -0.0452032 ], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embed_samples = embed([sample_sentence,\n",
    "                      \"This is a sample sentence where when you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23a4d53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each sentence has been encoded into a 512 dimension vector\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff8e6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (to create a feature extractor for next model)\n",
    "                                        name=\"UniversalSentenceEncoder\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fee4f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e4d274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fa6e9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " UniversalSentenceEncoder (K  (None, 512)              256797824 \n",
      " erasLayer)                                                      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7fe40aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20250307-034340\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 8ms/step - loss: 0.5100 - accuracy: 0.7824 - val_loss: 0.4448 - val_accuracy: 0.7992\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.4345 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4000 - accuracy: 0.8218 - val_loss: 0.4305 - val_accuracy: 0.8163\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3926 - accuracy: 0.8259 - val_loss: 0.4269 - val_accuracy: 0.8176\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3863 - accuracy: 0.8304 - val_loss: 0.4288 - val_accuracy: 0.8110\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58b02419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15300062],\n",
       "       [0.73603505],\n",
       "       [0.98860794],\n",
       "       [0.19721143],\n",
       "       [0.7298595 ],\n",
       "       [0.6702608 ],\n",
       "       [0.98279464],\n",
       "       [0.98031515],\n",
       "       [0.92465436],\n",
       "       [0.09441808]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21205d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af1555e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.10236220472441,\n",
       " 'precision': 0.8140341548215564,\n",
       " 'recall': 0.8110236220472441,\n",
       " 'f1': 0.809201931950287}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fcc814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 81.10, Difference: 1.84\n",
      "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
      "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
      "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare TF Hub model to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0bca1",
   "metadata": {},
   "source": [
    "# Model 7 using TensorFlow Hub Pretrained Sentence Encoder 10% of the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05bb1d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (split the already split train_sentences/train_labels)\n",
    "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
    "                                                                                                                            train_labels,\n",
    "                                                                                                                            test_size=0.1,\n",
    "                                                                                                                            random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60b648ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 6851\n",
      "Length of 10% training examples: 686\n"
     ]
    }
   ],
   "source": [
    "# Check length of 10 percent datasets\n",
    "print(f\"Total training examples: {len(train_sentences)}\")\n",
    "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "61c4ff84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    415\n",
       "1    271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data \n",
    "# (this should be close to the distribution of labels in the original train_labels)\n",
    "pd.Series(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a55442ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone model_6 but reset weights\n",
    "model_7 = tf.keras.models.clone_model(model_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a00bfbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c887b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " UniversalSentenceEncoder (K  (None, 512)              256797824 \n",
      " erasLayer)                                                      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary (will be same as model_6)\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cebc37f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20250307-034400\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 5s 32ms/step - loss: 0.6691 - accuracy: 0.6691 - val_loss: 0.6485 - val_accuracy: 0.7244\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5942 - accuracy: 0.8251 - val_loss: 0.5879 - val_accuracy: 0.7493\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.5158 - accuracy: 0.8222 - val_loss: 0.5355 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.4524 - accuracy: 0.8411 - val_loss: 0.5050 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.4096 - accuracy: 0.8426 - val_loss: 0.4883 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to 10% of the training data\n",
    "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
    "                              y=train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3312b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23453255],\n",
       "       [0.807578  ],\n",
       "       [0.9157539 ],\n",
       "       [0.30399552],\n",
       "       [0.55507994],\n",
       "       [0.83616275],\n",
       "       [0.82034314],\n",
       "       [0.85693026],\n",
       "       [0.84923124],\n",
       "       [0.12980618]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model trained on 10% of the data\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ad99759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99e1a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7751330918759862,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7668707484010339}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model results\n",
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b081693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_7_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8cdd88",
   "metadata": {},
   "source": [
    "# Comparing the performance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b4fa6db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>78.740157</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>76.377953</td>\n",
       "      <td>0.766310</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.761076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.770197</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.769428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>76.640420</td>\n",
       "      <td>0.771219</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.762791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>78.346457</td>\n",
       "      <td>0.787212</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.780780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>81.102362</td>\n",
       "      <td>0.814034</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.809202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.775133</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 79.265092   0.811139  0.792651  0.786219\n",
       "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
       "lstm                     76.377953   0.766310  0.763780  0.761076\n",
       "gru                      77.034121   0.770197  0.770341  0.769428\n",
       "bidirectional            76.640420   0.771219  0.766404  0.762791\n",
       "conv1d                   78.346457   0.787212  0.783465  0.780780\n",
       "tf_hub_sentence_encoder  81.102362   0.814034  0.811024  0.809202\n",
       "tf_hub_10_percent_data   77.034121   0.775133  0.770341  0.766871"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"gru\": model_3_results,\n",
    "                                  \"bidirectional\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
    "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6b6148cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f810d49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "80fa87be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d676bc8d",
   "metadata": {},
   "source": [
    "# Combining our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "493f9f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "32fc89bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7779066800449299,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7776698015840804}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from averaging the prediction probabilities\n",
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84f6a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our combined model's results to the results DataFrame\n",
    "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2abad6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the accuracy to the same scale as the rest of the results\n",
    "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8471e6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.766310</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.761076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.770197</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.769428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.771219</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.762791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.787212</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.780780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.814034</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.809202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.775133</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_results</th>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.777907</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.777670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy  precision    recall        f1\n",
       "baseline                 0.792651   0.811139  0.792651  0.786219\n",
       "simple_dense             0.787402   0.791492  0.787402  0.784697\n",
       "lstm                     0.763780   0.766310  0.763780  0.761076\n",
       "gru                      0.770341   0.770197  0.770341  0.769428\n",
       "bidirectional            0.766404   0.771219  0.766404  0.762791\n",
       "conv1d                   0.783465   0.787212  0.783465  0.780780\n",
       "tf_hub_sentence_encoder  0.811024   0.814034  0.811024  0.809202\n",
       "tf_hub_10_percent_data   0.770341   0.775133  0.770341  0.766871\n",
       "ensemble_results         0.778215   0.777907  0.778215  0.777670"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c3ea2",
   "metadata": {},
   "source": [
    "# Saving and loading a trained model (Model 6 the best results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e5bfec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5be59a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required with HDF5 format)\n",
    "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
    "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c25714b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 4s 25ms/step - loss: 0.4288 - accuracy: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.428787499666214, 0.8110235929489136]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "af312da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) UniversalSentenceEncoder_input with unsupported characters which will be renamed to universalsentenceencoder_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e7ee610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF Hub Sentence Encoder SavedModel\n",
    "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60baf05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step - loss: 0.4288 - accuracy: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.428787499666214, 0.8110235929489136]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded SavedModel format\n",
    "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64194bd",
   "metadata": {},
   "source": [
    "# Randomly getting samples from test dataset and predicting on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5d2368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Pred: 1, Prob: 0.9617922306060791\n",
      "Disaster\n",
      "Text:\n",
      "3 former executives to be prosecuted in Fukushima nuclear disaster http://t.co/EmWU8Xksdu\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Pred: 1, Prob: 0.9404222369194031\n",
      "Disaster\n",
      "Text:\n",
      "And Kolkata is struck by a Cyclonic Storm. Sumthng big is gonna happen 2day evng. Heavy rains nd a violent storm approachng. God help us.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Pred: 1, Prob: 0.9685485363006592\n",
      "Disaster\n",
      "Text:\n",
      "OMG there's a news chopper over a 3-acre mostly contained fire outside Forest Grove? #slownewsday ?\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Pred: 0, Prob: 0.04910268262028694\n",
      "Not Disaster\n",
      "Text:\n",
      "@asda bought this bargain dress and love it- cut colour pattern. Are you doing more? http://t.co/BnZm8K2AiM\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Pred: 1, Prob: 0.7682335376739502\n",
      "Disaster\n",
      "Text:\n",
      "Arsonist Sets NYC Vegetarian Restaurant on Fire: Police #NewYork - http://t.co/agn4cL4uSK\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Pred: 1, Prob: 0.8442429304122925\n",
      "Disaster\n",
      "Text:\n",
      "Let's appreciate that the group of people that everyone hates so much the police prevented mass casualties today in Nashville.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Pred: 0, Prob: 0.11677508056163788\n",
      "Not Disaster\n",
      "Text:\n",
      "The schematization to Maintain Facts Dependable By virtue of Obliteration...XMwTE\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Pred: 0, Prob: 0.0579950176179409\n",
      "Not Disaster\n",
      "Text:\n",
      "Now WoW folks I'm sorry for all the 'prepared' jokes that must be flooding your feeds right now.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Pred: 0, Prob: 0.06481736898422241\n",
      "Not Disaster\n",
      "Text:\n",
      "Bitch I'm a monster no good blood sucker\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Pred: 0, Prob: 0.10942018777132034\n",
      "Not Disaster\n",
      "Text:\n",
      "MomentsAtHill everyone hijacking NuNus and timas bikes ????\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
    "  pred = tf.round(pred_prob)\n",
    "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "  if int(pred)==1:\n",
    "        print(\"Disaster\")\n",
    "  else:\n",
    "    print(\"Not Disaster\")\n",
    "  print(f\"Text:\\n{test_sample}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "43e9d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_vectorizer\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_vectorizer\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vectorizer_model = tf.keras.Sequential([text_vectorizer])\n",
    "vectorizer_model.save('text_vectorizer', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1bf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
